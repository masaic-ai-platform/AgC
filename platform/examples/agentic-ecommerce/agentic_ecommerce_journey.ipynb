{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic E-commerce Journey\n",
    "\n",
    "This notebook demonstrates a complete 3-step agentic e-commerce journey using MCP (Model Context Protocol) tools orchestrated through the Open Responses API.\n",
    "\n",
    "## Journey Overview\n",
    "\n",
    "1. **Product Search**: Search for products using Shopify's catalog search MCP tool\n",
    "2. **Scene Generation**: Create contextual images showing how the product would look in a real environment\n",
    "3. **Payment Confirmation**: Fetch and display payment and order details using Razorpay MCP tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete! Ready to start the agentic e-commerce journey.\n",
      "üîß OpenAI clients initialized for all models.\n",
      "‚ö†Ô∏è Remember to update all API keys before running the journey!\n"
     ]
    }
   ],
   "source": [
    "# Required imports\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import time\n",
    "from typing import Iterator, Dict, Any\n",
    "\n",
    "# API Key Configuration for Different Models\n",
    "# Update these with your actual API keys\n",
    "\n",
    "# Step 1: LLAMA model API key (TogetherAI)\n",
    "LLAMA_API_KEY = \"YOUR_TOGETHERAI_API_KEY\"\n",
    "\n",
    "# Step 2: OpenAI model API key \n",
    "OPENAI_API_KEY = \"YOUR_OPENAI_API_KEY\"\n",
    "\n",
    "# Step 3: Claude model API key (Anthropic)\n",
    "CLAUDE_API_KEY = \"YOUR_ANTHROPIC_API_KEY\"\n",
    "\n",
    "# Additional API keys\n",
    "RAZORPAY_API_KEY = \"YOUR_RAZORPAY_API_KEY\"\n",
    "\n",
    "# Base URL for Open Responses API\n",
    "OPEN_RESPONSES_BASE_URL = \"http://open-responses:6644/v1\"\n",
    "\n",
    "# Create OpenAI clients for each model with their respective API keys\n",
    "def create_client(api_key: str) -> OpenAI:\n",
    "    \"\"\"Create OpenAI client with custom base URL and API key\"\"\"\n",
    "    return OpenAI(\n",
    "        api_key=api_key,\n",
    "        base_url=OPEN_RESPONSES_BASE_URL\n",
    "    )\n",
    "\n",
    "# Initialize clients for each model\n",
    "llama_client = create_client(LLAMA_API_KEY)\n",
    "openai_client = create_client(OPENAI_API_KEY)\n",
    "claude_client = create_client(CLAUDE_API_KEY)\n",
    "\n",
    "print(\"Setup complete! Ready to start the agentic e-commerce journey.\")\n",
    "print(\"üîß OpenAI clients initialized for all models.\")\n",
    "print(\"‚ö†Ô∏è Remember to update all API keys before running the journey!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Custom streaming event handler loaded!\n"
     ]
    }
   ],
   "source": [
    "# Custom Streaming Event Handler for Open Responses API\n",
    "def handle_streaming_events(stream, step_name: str = \"Process\"):\n",
    "    \"\"\"\n",
    "    Handle streaming events from Open Responses API\n",
    "    Properly parses event objects and extracts content\n",
    "    Returns the accumulated response text\n",
    "    \"\"\"\n",
    "    full_response = \"\"\n",
    "    response_started = False\n",
    "    \n",
    "    print(f\"üîÑ Starting {step_name}...\")\n",
    "    \n",
    "    try:\n",
    "        for event in stream:\n",
    "            # Extract event type from the event object\n",
    "            event_type = getattr(event, 'type', None)\n",
    "            \n",
    "            if event_type:\n",
    "                # Handle specific event types based on the new format\n",
    "                if event_type == \"response.created\":\n",
    "                    print(f\"üìù Response created\")\n",
    "                    response_started = True\n",
    "                    \n",
    "                elif event_type == \"response.in_progress\":\n",
    "                    print(f\"‚öôÔ∏è  In progress...\")\n",
    "                    \n",
    "                elif \"executing\" in event_type or \"in_progress\" in event_type:\n",
    "                    # Extract tool name if available\n",
    "                    tool_name = event_type\n",
    "                    print(f\"‚öôÔ∏è  Executing {tool_name}...\")\n",
    "                    \n",
    "                elif \"completed\" in event_type:\n",
    "                    if event_type == \"response.completed\":\n",
    "                        print(f\"‚úÖ Response completed\")\n",
    "                    else:\n",
    "                        tool_name = event_type\n",
    "                        print(f\"‚úÖ {tool_name} completed\")\n",
    "                    \n",
    "                elif event_type == \"response.output_text.delta\":\n",
    "                    # Extract delta content from the event\n",
    "                    if hasattr(event, 'delta'):\n",
    "                        delta_content = event.delta\n",
    "                        print(delta_content, end='', flush=True)\n",
    "                        full_response += delta_content\n",
    "                    # Also check if it's in a nested structure\n",
    "                    elif hasattr(event, 'choices') and event.choices:\n",
    "                        if hasattr(event.choices[0], 'delta') and hasattr(event.choices[0].delta, 'content'):\n",
    "                            content = event.choices[0].delta.content\n",
    "                            if content:\n",
    "                                print(content, end='', flush=True)\n",
    "                                full_response += content\n",
    "                                \n",
    "                elif event_type == \"response.output_text.done\":\n",
    "                    # Final text output - we've already streamed it\n",
    "                    pass\n",
    "                    \n",
    "                elif event_type == \"response.output_item.added\":\n",
    "                    print(f\"üîß Tool call added\")\n",
    "                    \n",
    "                # For other events, show minimal info\n",
    "                elif not any(x in event_type for x in [\"sequence_number\", \"isValid\"]):\n",
    "                    print(f\"üîç {event_type}\")\n",
    "            else:\n",
    "                # Try to extract content from choices/delta structure (fallback)\n",
    "                if hasattr(event, 'choices') and event.choices:\n",
    "                    if hasattr(event.choices[0], 'delta') and hasattr(event.choices[0].delta, 'content'):\n",
    "                        content = event.choices[0].delta.content\n",
    "                        if content:\n",
    "                            print(content, end='', flush=True)\n",
    "                            full_response += content\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ö†Ô∏è Error processing stream: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "    if not response_started:\n",
    "        print(\"‚ö†Ô∏è No response.created event detected\")\n",
    "        \n",
    "    print(f\"\\n\\n‚úÖ {step_name} completed!\")\n",
    "    return full_response\n",
    "\n",
    "print(\"üîß Custom streaming event handler loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Product Search\n",
    "\n",
    "In this step, we use the Shopify MCP tool to search for products in the catalog. The `search_shop_catalog` tool will help us find products and retrieve complete details including images.\n",
    "\n",
    "### Configuration:\n",
    "- **Model**: `togetherai@meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8`\n",
    "- **MCP Server**: Shopify at `https://allbirds.com/api/mcp`\n",
    "- **Tool**: `search_shop_catalog`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Searching for HP printer using LLAMA model...\n",
      "üîë Using API Key: tgp_v1_JNQ...\n",
      "üîÑ Starting Product Search...\n",
      "üìù Response created\n",
      "‚öôÔ∏è  In progress...\n",
      "üîß Tool call added\n",
      "‚öôÔ∏è  Executing response.mcp_call.shopify_search_shop_catalog.in_progress...\n",
      "‚öôÔ∏è  Executing response.mcp_call.shopify_search_shop_catalog.executing...\n",
      "‚úÖ response.mcp_call.shopify_search_shop_catalog.completed completed\n",
      "The cheapest men's sneaker is the Men's Tree Runner - Mist (White Sole) priced at $100. It is a breathable and lightweight sneaker made with responsibly sourced eucalyptus tree fiber. The shoe is available in various sizes (8-14) and has multiple images available.\n",
      "\n",
      "Here are the details of the product:\n",
      "\n",
      "* Title: Men's Tree Runner - Mist (White Sole)\n",
      "* Price: $100\n",
      "* Description: The Allbirds Tree Runner is a breathable and lightweight sneaker made with responsibly sourced eucalyptus tree fiber that feels silky smooth and cool on your skin. These shoes are perfect for everyday casual wear, walking, and warmer weather.\n",
      "* URL: https://www.allbirds.com/products/mens-tree-runners-mist\n",
      "* Image URL: https://cdn.shopify.com/s/files/1/1104/4168/files/TR3MMST080_SHOE_LEFT_GLOBAL_MENS_TREE_RUNNER_MIST_WHITE_9959c126-77c8-42fc-aef3-7d6093c605bf.png?v=1751166590\n",
      "* Available sizes: 8, 9, 10, 11, 12, 13, 14\n",
      "\n",
      "If you would like to see more products or have any other questions, feel free to ask.‚úÖ Response completed\n",
      "\n",
      "\n",
      "‚úÖ Product Search completed!\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Search for HP printer using Shopify MCP tool (LLAMA Model)\n",
    "def search_product():\n",
    "    print(\"üîç Searching for HP printer using LLAMA model...\")\n",
    "    print(f\"üîë Using API Key: {LLAMA_API_KEY[:10]}...\" if LLAMA_API_KEY != \"YOUR_TOGETHERAI_API_KEY\" else \"‚ö†Ô∏è Please set LLAMA_API_KEY\")\n",
    "    \n",
    "    try:\n",
    "        # Create streaming response using OpenAI SDK\n",
    "        stream = llama_client.responses.create(\n",
    "            model=\"togetherai@meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8\",\n",
    "            tools=[\n",
    "                {\n",
    "                    \"type\": \"mcp\",\n",
    "                    \"server_label\": \"shopify\",\n",
    "                    \"server_url\": \"https://allbirds.com/api/mcp\",\n",
    "                    \"allowed_tools\": [\"search_shop_catalog\"]\n",
    "                }\n",
    "            ],\n",
    "            instructions=(\n",
    "                \"Use search_shop_catalog to search the product and then bring complete details \"\n",
    "                \"of the product including all available images. Do not mention names of tools in the response\"\n",
    "            ),\n",
    "            input=\"Find me one cheapest men's sneaker\",\n",
    "            stream=True\n",
    "        )\n",
    "        \n",
    "        # Use custom streaming handler to process events\n",
    "        full_response = handle_streaming_events(stream, \"Product Search\")\n",
    "        return full_response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error during product search: {e}\")\n",
    "        return None\n",
    "\n",
    "# Execute the product search (uncomment to run)\n",
    "search_result = search_product()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Scene Generation for Product Selection\n",
    "\n",
    "In this step, we create a contextual image showing how the selected product would look in a real environment (study table). This uses image generation MCP tools to help customers visualize the product in their space.\n",
    "\n",
    "### Configuration:\n",
    "- **Model**: `openai@gpt-4.1-mini`\n",
    "- **MCP Server**: Image generation at if running without docker `http://localhost:8086/mcp` if running within docker `http://demo-mcp-server:8086/mcp`\n",
    "- **Tools**: `image_to_base64`, `img_scene_generator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé® Generating scene image using OpenAI model...\n",
      "üîë Using API Key: sk-proj-DZ...\n",
      "üîÑ Starting Scene Generation...\n",
      "üìù Response created\n",
      "‚öôÔ∏è  In progress...\n",
      "üîß Tool call added\n",
      "‚öôÔ∏è  Executing response.mcp_call.img_mcp_image_to_base64.in_progress...\n",
      "‚öôÔ∏è  Executing response.mcp_call.img_mcp_image_to_base64.executing...\n",
      "‚úÖ response.mcp_call.img_mcp_image_to_base64.completed completed\n",
      "üîß Tool call added\n",
      "‚öôÔ∏è  Executing response.mcp_call.img_mcp_img_scene_generator.in_progress...\n",
      "‚öôÔ∏è  Executing response.mcp_call.img_mcp_img_scene_generator.executing...\n",
      "‚úÖ response.mcp_call.img_mcp_img_scene_generator.completed completed\n",
      "Here is the generated image of how the Men's Tree Runner Mist White shoes will look on your study table with typical study items like books, a laptop, and a cup of coffee, all under warm and inviting lighting: \n",
      "http://localhost:8086/generated_image_1754632396.png Response completed\n",
      "\n",
      "\n",
      "‚úÖ Scene Generation completed!\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Generate scene image showing printer on study table (OpenAI Model)\n",
    "def generate_scene():\n",
    "    print(\"üé® Generating scene image using OpenAI model...\")\n",
    "    print(f\"üîë Using API Key: {OPENAI_API_KEY[:10]}...\" if OPENAI_API_KEY != \"YOUR_OPENAI_API_KEY\" else \"‚ö†Ô∏è Please set OPENAI_API_KEY\")\n",
    "    \n",
    "    try:\n",
    "        # Create streaming response using OpenAI SDK with structured output\n",
    "        stream = openai_client.responses.create(\n",
    "            model=\"openai@gpt-4.1-mini\",\n",
    "            tools=[\n",
    "                {\n",
    "                    \"type\": \"mcp\",\n",
    "                    \"server_label\": \"img_mcp\",\n",
    "                    \"server_url\": \"http://demo-mcp-server:8086/mcp\",\n",
    "                    \"allowed_tools\": [\n",
    "                        \"image_to_base64\",\n",
    "                        \"img_scene_generator\"\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            instructions=(\n",
    "                \"Use tool image_to_base64 to generate base64encoded String from provided URL of image \"\n",
    "                \"and then use tool img_scene_generator to generate the image for the scene with input prompt \"\n",
    "                \"and encodedFilePath returned by the tool image_to_base64. If the image is generated then return the generated scene image url.\"\n",
    "            ),\n",
    "            input=(\n",
    "                \"How it will look like on my study table. Create new image of described situation using tools \"\n",
    "                \"and object available here https://cdn.shopify.com/s/files/1/1104/4168/files/TR3MMST080_SHOE_LEFT_GLOBAL_MENS_TREE_RUNNER_MIST_WHITE_9959c126-77c8-42fc-aef3-7d6093c605bf.png?v=1751166590\"\n",
    "            ),\n",
    "            stream=True\n",
    "        )\n",
    "        \n",
    "        # Use custom streaming handler to process events\n",
    "        full_response = handle_streaming_events(stream, \"Scene Generation\")\n",
    "        \n",
    "        # # Try to parse the JSON response\n",
    "        # try:\n",
    "        #     scene_data = json.loads(full_response.strip())\n",
    "        #     print(f\"\\nüìã Scene Description: {scene_data.get('situationDescription', 'N/A')}\")\n",
    "        #     print(f\"üñºÔ∏è Generated Image URL: {scene_data.get('image_url', 'N/A')}\")\n",
    "        #     print(f\"‚úÖ Completed Stage: {scene_data.get('completedStage', 'N/A')}\")\n",
    "        #     return scene_data\n",
    "        # except json.JSONDecodeError:\n",
    "        #     print(\"‚ö†Ô∏è Could not parse JSON response\")\n",
    "        #     return {\"raw_response\": full_response}\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error during scene generation: {e}\")\n",
    "        return None\n",
    "\n",
    "# Execute the scene generation (uncomment to run)\n",
    "scene_result = generate_scene()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Payment Confirmation\n",
    "\n",
    "In this final step, we fetch payment and order details using Razorpay MCP tools. This demonstrates how to retrieve transaction information and present it in a user-friendly format.\n",
    "\n",
    "### Configuration:\n",
    "- **Model**: `claude@claude-sonnet-4-20250514`\n",
    "- **MCP Server**: Razorpay at `https://mcp.razorpay.com/sse`\n",
    "- **Tools**: `fetch_payment`, `fetch_order`\n",
    "- **Authentication**: Bearer token required in headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí≥ Fetching payment and order details using Claude model...\n",
      "üîë Using Claude API Key: sk-ant-api...\n",
      "üîë Using Razorpay API Key: cnpwX2xpdm...\n",
      "üîÑ Starting Payment Confirmation...\n",
      "üìù Response created\n",
      "‚öôÔ∏è  In progress...\n",
      "I see you've provided a placeholder `{payment_id}` rather than an actual payment ID. To fetch the payment and order details, I need the actual payment ID value.\n",
      "\n",
      "Could you please provide the specific payment ID you'd like me to look up? It should be a string of characters that uniquely identifies the payment in Razorpay's system.‚úÖ Response completed\n",
      "\n",
      "\n",
      "‚úÖ Payment Confirmation completed!\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Fetch payment and order details using Razorpay MCP tools (Claude Model)\n",
    "def confirm_payment():\n",
    "    print(\"üí≥ Fetching payment and order details using Claude model...\")\n",
    "    print(f\"üîë Using Claude API Key: {CLAUDE_API_KEY[:10]}...\" if CLAUDE_API_KEY != \"YOUR_ANTHROPIC_API_KEY\" else \"‚ö†Ô∏è Please set CLAUDE_API_KEY\")\n",
    "    print(f\"üîë Using Razorpay API Key: {RAZORPAY_API_KEY[:10]}...\" if RAZORPAY_API_KEY != \"YOUR_RAZORPAY_API_KEY\" else \"‚ö†Ô∏è Please set RAZORPAY_API_KEY\")\n",
    "    \n",
    "    try:\n",
    "        # Create streaming response using OpenAI SDK\n",
    "        stream = claude_client.responses.create(\n",
    "            model=\"claude@claude-sonnet-4-20250514\",\n",
    "            tools=[\n",
    "                {\n",
    "                    \"type\": \"mcp\",\n",
    "                    \"server_label\": \"razorpay\",\n",
    "                    \"server_url\": \"https://mcp.razorpay.com/sse\",\n",
    "                    \"allowed_tools\": [\n",
    "                        \"fetch_payment\",\n",
    "                        \"fetch_order\"\n",
    "                    ],\n",
    "                    \"headers\": {\n",
    "                        \"Authorization\": f\"Bearer {RAZORPAY_API_KEY}\"\n",
    "                    }\n",
    "                }\n",
    "            ],\n",
    "            instructions=(\n",
    "                \"Use fetch_payment tool by passing payment id provided by the user, \"\n",
    "                \"get the order id from payment details response then fetch order details \"\n",
    "                \"using fetch_order tool and return order details in markdown format\"\n",
    "            ),\n",
    "            input=\"payment id {payment_id}\",\n",
    "            store=True,\n",
    "            stream=True\n",
    "        )\n",
    "        \n",
    "        # Use custom streaming handler to process events\n",
    "        full_response = handle_streaming_events(stream, \"Payment Confirmation\")\n",
    "        return full_response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error during payment confirmation: {e}\")\n",
    "        return None\n",
    "\n",
    "# Execute the payment confirmation (uncomment to run)\n",
    "payment_result = confirm_payment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Test Functions\n",
    "\n",
    "Uncomment any of the lines below to test individual functions:\n",
    "\n",
    "```python\n",
    "# Test individual functions:\n",
    "search_result = search_product()\n",
    "scene_result = generate_scene()\n",
    "payment_result = confirm_payment()\n",
    "```\n",
    "\n",
    "### Expected Outputs:\n",
    "- **Step 1**: Product details with images (powered by LLAMA)\n",
    "- **Step 2**: JSON response with scene description and generated image URL (powered by OpenAI)\n",
    "- **Step 3**: Payment and order details in markdown format (powered by Claude)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
