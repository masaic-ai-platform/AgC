{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic E-commerce Journey\n",
    "\n",
    "This notebook demonstrates a complete 3-step agentic e-commerce journey using MCP (Model Context Protocol) tools orchestrated through the Open Responses API.\n",
    "\n",
    "## Journey Overview\n",
    "\n",
    "1. **Product Search**: Search for products using Shopify's catalog search MCP tool\n",
    "2. **Scene Generation**: Create contextual images showing how the product would look in a real environment\n",
    "3. **Payment Confirmation**: Fetch and display payment and order details using Razorpay MCP tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete! Ready to start the agentic e-commerce journey.\n",
      "üîß OpenAI clients initialized for all models.\n",
      "‚ö†Ô∏è Remember to update all API keys before running the journey!\n"
     ]
    }
   ],
   "source": [
    "# Required imports\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import time\n",
    "from typing import Iterator, Dict, Any\n",
    "\n",
    "# API Key Configuration for Different Models\n",
    "# Update these with your actual API keys\n",
    "\n",
    "# Step 1: LLAMA model API key (TogetherAI)\n",
    "LLAMA_API_KEY = \"YOUR_TOGETHERAI_API_KEY\"\n",
    "\n",
    "# Step 2: OpenAI model API key \n",
    "OPENAI_API_KEY = \"YOUR_OPENAI_API_KEY\"\n",
    "\n",
    "# Step 3: Claude model API key (Anthropic)\n",
    "CLAUDE_API_KEY = \"YOUR_ANTHROPIC_API_KEY\"\n",
    "\n",
    "# Additional API keys\n",
    "RAZORPAY_API_KEY = \"YOUR_RAZORPAY_API_KEY\"\n",
    "\n",
    "# Base URL for Open Responses API\n",
    "OPEN_RESPONSES_BASE_URL = \"http://open-responses:8080/v1\"\n",
    "\n",
    "# Create OpenAI clients for each model with their respective API keys\n",
    "def create_client(api_key: str) -> OpenAI:\n",
    "    \"\"\"Create OpenAI client with custom base URL and API key\"\"\"\n",
    "    return OpenAI(\n",
    "        api_key=api_key,\n",
    "        base_url=OPEN_RESPONSES_BASE_URL\n",
    "    )\n",
    "\n",
    "# Initialize clients for each model\n",
    "llama_client = create_client(LLAMA_API_KEY)\n",
    "openai_client = create_client(OPENAI_API_KEY)\n",
    "claude_client = create_client(CLAUDE_API_KEY)\n",
    "\n",
    "print(\"Setup complete! Ready to start the agentic e-commerce journey.\")\n",
    "print(\"üîß OpenAI clients initialized for all models.\")\n",
    "print(\"‚ö†Ô∏è Remember to update all API keys before running the journey!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Custom streaming event handler loaded!\n"
     ]
    }
   ],
   "source": [
    "# Custom Streaming Event Handler for Open Responses API\n",
    "def handle_streaming_events(stream, step_name: str = \"Process\"):\n",
    "    \"\"\"\n",
    "    Handle streaming events from Open Responses API\n",
    "    Properly parses event objects and extracts content\n",
    "    Returns the accumulated response text\n",
    "    \"\"\"\n",
    "    full_response = \"\"\n",
    "    response_started = False\n",
    "    \n",
    "    print(f\"üîÑ Starting {step_name}...\")\n",
    "    \n",
    "    try:\n",
    "        for event in stream:\n",
    "            # Extract event type from the event object\n",
    "            event_type = getattr(event, 'type', None)\n",
    "            \n",
    "            if event_type:\n",
    "                # Handle specific event types based on the new format\n",
    "                if event_type == \"response.created\":\n",
    "                    print(f\"üìù Response created\")\n",
    "                    response_started = True\n",
    "                    \n",
    "                elif event_type == \"response.in_progress\":\n",
    "                    print(f\"‚öôÔ∏è  In progress...\")\n",
    "                    \n",
    "                elif \"executing\" in event_type or \"in_progress\" in event_type:\n",
    "                    # Extract tool name if available\n",
    "                    tool_name = event_type.split('.')[-2] if '.' in event_type else 'task'\n",
    "                    print(f\"‚öôÔ∏è  Executing {tool_name}...\")\n",
    "                    \n",
    "                elif \"completed\" in event_type:\n",
    "                    if event_type == \"response.completed\":\n",
    "                        print(f\"‚úÖ Response completed\")\n",
    "                    else:\n",
    "                        tool_name = event_type.split('.')[-2] if '.' in event_type else 'task'\n",
    "                        print(f\"‚úÖ {tool_name} completed\")\n",
    "                    \n",
    "                elif event_type == \"response.output_text.delta\":\n",
    "                    # Extract delta content from the event\n",
    "                    if hasattr(event, 'delta'):\n",
    "                        delta_content = event.delta\n",
    "                        print(delta_content, end='', flush=True)\n",
    "                        full_response += delta_content\n",
    "                    # Also check if it's in a nested structure\n",
    "                    elif hasattr(event, 'choices') and event.choices:\n",
    "                        if hasattr(event.choices[0], 'delta') and hasattr(event.choices[0].delta, 'content'):\n",
    "                            content = event.choices[0].delta.content\n",
    "                            if content:\n",
    "                                print(content, end='', flush=True)\n",
    "                                full_response += content\n",
    "                                \n",
    "                elif event_type == \"response.output_text.done\":\n",
    "                    # Final text output - we've already streamed it\n",
    "                    pass\n",
    "                    \n",
    "                elif event_type == \"response.output_item.added\":\n",
    "                    print(f\"üîß Tool call added\")\n",
    "                    \n",
    "                # For other events, show minimal info\n",
    "                elif not any(x in event_type for x in [\"sequence_number\", \"isValid\"]):\n",
    "                    print(f\"üîç {event_type}\")\n",
    "            else:\n",
    "                # Try to extract content from choices/delta structure (fallback)\n",
    "                if hasattr(event, 'choices') and event.choices:\n",
    "                    if hasattr(event.choices[0], 'delta') and hasattr(event.choices[0].delta, 'content'):\n",
    "                        content = event.choices[0].delta.content\n",
    "                        if content:\n",
    "                            print(content, end='', flush=True)\n",
    "                            full_response += content\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ö†Ô∏è Error processing stream: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "    if not response_started:\n",
    "        print(\"‚ö†Ô∏è No response.created event detected\")\n",
    "        \n",
    "    print(f\"\\n\\n‚úÖ {step_name} completed!\")\n",
    "    return full_response\n",
    "\n",
    "print(\"üîß Custom streaming event handler loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Product Search\n",
    "\n",
    "In this step, we use the Shopify MCP tool to search for products in the catalog. The `search_shop_catalog` tool will help us find products and retrieve complete details including images.\n",
    "\n",
    "### Configuration:\n",
    "- **Model**: `togetherai@meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8`\n",
    "- **MCP Server**: Shopify at `https://axzx8j-61.myshopify.com/api/mcp`\n",
    "- **Tool**: `search_shop_catalog`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Searching for HP printer using LLAMA model...\n",
      "üîë Using API Key: tgp_v1_JNQ...\n",
      "üîÑ Starting Product Search...\n",
      "üìù Response created\n",
      "‚öôÔ∏è  In progress...\n",
      "üîß Tool call added\n",
      "‚öôÔ∏è  Executing shopify_search_shop_catalog...\n",
      "‚öôÔ∏è  Executing shopify_search_shop_catalog...\n",
      "‚úÖ shopify_search_shop_catalog completed\n",
      "### HP DeskJet Color Inkjet Printer\n",
      "\n",
      "**Price:** ‚Çπ5,499\n",
      "\n",
      "**Description:** HP DeskJet Ink Advantage 2878 All-in-One Wi-Fi Color Inkjet Printer. It can Print, Scan, and Copy. Ideal for home and small office use.\n",
      "\n",
      "**Key Features:**\n",
      "\n",
      "* General Type: Multi-function (Print, Copy, Scan)\n",
      "* Printing Method: Inkjet\n",
      "* Output: Color\n",
      "* Print Max Resolution: \n",
      "  - Color: 4800 √ó 1200 dpi\n",
      "  - Mono: 1200 √ó 1200 dpi\n",
      "* Speed: \n",
      "  - Color: 5.5 ppm\n",
      "  - Mono: 7.5 ppm\n",
      "* Connectivity: USB 2.0, Wireless\n",
      "* Mobile Support: HP Smart App, Chrome OS, Apple AirPrint, Mopria Print Service\n",
      "* System Requirements: Windows 10 / 11, macOS 10.14 or later, Chrome OS\n",
      "* Ink Compatibility: \n",
      "  - Black Cartridge: HP 682 Black Original Ink\n",
      "  - Color Cartridge: HP 682 Tri-color Original Ink\n",
      "* Power Usage: \n",
      "  - Manual-Off: 0.3 W\n",
      "  - Active: 2.8 W\n",
      "* Dimensions (W √ó D √ó H): 16.7\" √ó 11.9\" √ó 5.87\"\n",
      "* Weight: 3.42 kg\n",
      "\n",
      "**What's in the Box:**\n",
      "1. Printer\n",
      "2. HP 682 Setup Cartridges (Black & Tri-color)\n",
      "3. Power cord (1.5 m)\n",
      "4. Setup Guides & Regulatory Flyer\n",
      "\n",
      "**Image:** \n",
      "[Printer Front](https://cdn.shopify.com/s/files/1/0948/4369/9488/files/printer-front.avif?v=1750994570)\n",
      "\n",
      "You can view more details or purchase this product on the [product page](https://axzx8j-61.myshopify.com/products/hp-deskjet-color-inkjet-printer).‚úÖ Response completed\n",
      "\n",
      "\n",
      "‚úÖ Product Search completed!\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Search for HP printer using Shopify MCP tool (LLAMA Model)\n",
    "def search_product():\n",
    "    print(\"üîç Searching for HP printer using LLAMA model...\")\n",
    "    print(f\"üîë Using API Key: {LLAMA_API_KEY[:10]}...\" if LLAMA_API_KEY != \"YOUR_TOGETHERAI_API_KEY\" else \"‚ö†Ô∏è Please set LLAMA_API_KEY\")\n",
    "    \n",
    "    try:\n",
    "        # Create streaming response using OpenAI SDK\n",
    "        stream = llama_client.responses.create(\n",
    "            model=\"togetherai@meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8\",\n",
    "            tools=[\n",
    "                {\n",
    "                    \"type\": \"mcp\",\n",
    "                    \"server_label\": \"shopify\",\n",
    "                    \"server_url\": \"https://axzx8j-61.myshopify.com/api/mcp\",\n",
    "                    \"allowed_tools\": [\"search_shop_catalog\"]\n",
    "                }\n",
    "            ],\n",
    "            instructions=(\n",
    "                \"Use search_shop_catalog to search the product and then bring complete details \"\n",
    "                \"of the product including all available images. Do not mention names of tools in the response\"\n",
    "            ),\n",
    "            input=\"Find me HP printer\",\n",
    "            stream=True\n",
    "        )\n",
    "        \n",
    "        # Use custom streaming handler to process events\n",
    "        full_response = handle_streaming_events(stream, \"Product Search\")\n",
    "        return full_response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error during product search: {e}\")\n",
    "        return None\n",
    "\n",
    "# Execute the product search (uncomment to run)\n",
    "search_result = search_product()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Scene Generation for Product Selection\n",
    "\n",
    "In this step, we create a contextual image showing how the selected product would look in a real environment (study table). This uses image generation MCP tools to help customers visualize the product in their space.\n",
    "\n",
    "### Configuration:\n",
    "- **Model**: `openai@gpt-4.1-mini`\n",
    "- **MCP Server**: Image generation at if running without docker `http://localhost:8086/mcp` if running within docker `http://demo-mcp-server:8086/mcp`\n",
    "- **Tools**: `image_to_base64`, `img_scene_generator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé® Generating scene image using OpenAI model...\n",
      "üîë Using API Key: sk-proj-uz...\n",
      "üîÑ Starting Scene Generation...\n",
      "üìù Response created\n",
      "‚öôÔ∏è  In progress...\n",
      "üîß Tool call added\n",
      "‚öôÔ∏è  Executing img_mcp_image_to_base64...\n",
      "‚öôÔ∏è  Executing img_mcp_image_to_base64...\n",
      "‚úÖ img_mcp_image_to_base64 completed\n",
      "üîß Tool call added\n",
      "‚öôÔ∏è  Executing img_mcp_img_scene_generator...\n",
      "‚öôÔ∏è  Executing img_mcp_img_scene_generator...\n",
      "‚úÖ img_mcp_img_scene_generator completed\n",
      "I have created an image showing how the printer will look on your study table. The table has a wooden texture with the sleek printer placed on the corner. There are stacked books on one side, an open laptop in the center, and a notebook with a pen next to it. The scene is illuminated by natural daylight, creating a cozy and productive atmosphere. You can view the generated image here: http://localhost:8086/generated_image_1751442044.png\n",
      "\n",
      "completedStage=select‚úÖ Response completed\n",
      "\n",
      "\n",
      "‚úÖ Scene Generation completed!\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Generate scene image showing printer on study table (OpenAI Model)\n",
    "def generate_scene():\n",
    "    print(\"üé® Generating scene image using OpenAI model...\")\n",
    "    print(f\"üîë Using API Key: {OPENAI_API_KEY[:10]}...\" if OPENAI_API_KEY != \"YOUR_OPENAI_API_KEY\" else \"‚ö†Ô∏è Please set OPENAI_API_KEY\")\n",
    "    \n",
    "    try:\n",
    "        # Create streaming response using OpenAI SDK with structured output\n",
    "        stream = openai_client.responses.create(\n",
    "            model=\"openai@gpt-4.1-mini\",\n",
    "            tools=[\n",
    "                {\n",
    "                    \"type\": \"mcp\",\n",
    "                    \"server_label\": \"img_mcp\",\n",
    "                    \"server_url\": \"http://demo-mcp-server:8086/mcp\",\n",
    "                    \"allowed_tools\": [\n",
    "                        \"image_to_base64\",\n",
    "                        \"img_scene_generator\"\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            instructions=(\n",
    "                \"Use tool image_to_base64 to generate base64encoded String from provided URL of image \"\n",
    "                \"and then use tool img_scene_generator to generate the image for the scene with input prompt \"\n",
    "                \"and encodedFilePath returned by the tool image_to_base64. If the image is generated then return \"\n",
    "                \"the completedStage=select else not_achieved.\"\n",
    "            ),\n",
    "            input=(\n",
    "                \"How it will look like on my study table. Create new image of described situation using tools \"\n",
    "                \"and object available here https://cdn.shopify.com/s/files/1/0948/4369/9488/files/printer-front.avif?v=1750994570\"\n",
    "            ),\n",
    "            stream=True\n",
    "        )\n",
    "        \n",
    "        # Use custom streaming handler to process events\n",
    "        full_response = handle_streaming_events(stream, \"Scene Generation\")\n",
    "        \n",
    "        # # Try to parse the JSON response\n",
    "        # try:\n",
    "        #     scene_data = json.loads(full_response.strip())\n",
    "        #     print(f\"\\nüìã Scene Description: {scene_data.get('situationDescription', 'N/A')}\")\n",
    "        #     print(f\"üñºÔ∏è Generated Image URL: {scene_data.get('image_url', 'N/A')}\")\n",
    "        #     print(f\"‚úÖ Completed Stage: {scene_data.get('completedStage', 'N/A')}\")\n",
    "        #     return scene_data\n",
    "        # except json.JSONDecodeError:\n",
    "        #     print(\"‚ö†Ô∏è Could not parse JSON response\")\n",
    "        #     return {\"raw_response\": full_response}\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error during scene generation: {e}\")\n",
    "        return None\n",
    "\n",
    "# Execute the scene generation (uncomment to run)\n",
    "scene_result = generate_scene()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Payment Confirmation\n",
    "\n",
    "In this final step, we fetch payment and order details using Razorpay MCP tools. This demonstrates how to retrieve transaction information and present it in a user-friendly format.\n",
    "\n",
    "### Configuration:\n",
    "- **Model**: `claude@claude-sonnet-4-20250514`\n",
    "- **MCP Server**: Razorpay at `https://mcp.razorpay.com/sse`\n",
    "- **Tools**: `fetch_payment`, `fetch_order`\n",
    "- **Authentication**: Bearer token required in headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí≥ Fetching payment and order details using Claude model...\n",
      "üîë Using Claude API Key: sk-ant-api...\n",
      "üîë Using Razorpay API Key: cnpwX2xpdm...\n",
      "üîÑ Starting Payment Confirmation...\n",
      "üìù Response created\n",
      "‚öôÔ∏è  In progress...\n",
      "I notice you've provided a placeholder `{payment_id}` instead of an actual payment ID. To fetch the payment and order details, I need the specific payment ID value.\n",
      "\n",
      "Could you please provide the actual payment ID? It should look something like `pay_XXXXXXXXXX` (where X represents alphanumeric characters).‚úÖ Response completed\n",
      "\n",
      "\n",
      "‚úÖ Payment Confirmation completed!\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Fetch payment and order details using Razorpay MCP tools (Claude Model)\n",
    "def confirm_payment():\n",
    "    print(\"üí≥ Fetching payment and order details using Claude model...\")\n",
    "    print(f\"üîë Using Claude API Key: {CLAUDE_API_KEY[:10]}...\" if CLAUDE_API_KEY != \"YOUR_ANTHROPIC_API_KEY\" else \"‚ö†Ô∏è Please set CLAUDE_API_KEY\")\n",
    "    print(f\"üîë Using Razorpay API Key: {RAZORPAY_API_KEY[:10]}...\" if RAZORPAY_API_KEY != \"YOUR_RAZORPAY_API_KEY\" else \"‚ö†Ô∏è Please set RAZORPAY_API_KEY\")\n",
    "    \n",
    "    try:\n",
    "        # Create streaming response using OpenAI SDK\n",
    "        stream = claude_client.responses.create(\n",
    "            model=\"claude@claude-sonnet-4-20250514\",\n",
    "            tools=[\n",
    "                {\n",
    "                    \"type\": \"mcp\",\n",
    "                    \"server_label\": \"razorpay\",\n",
    "                    \"server_url\": \"https://mcp.razorpay.com/sse\",\n",
    "                    \"allowed_tools\": [\n",
    "                        \"fetch_payment\",\n",
    "                        \"fetch_order\"\n",
    "                    ],\n",
    "                    \"headers\": {\n",
    "                        \"Authorization\": f\"Bearer {RAZORPAY_API_KEY}\"\n",
    "                    }\n",
    "                }\n",
    "            ],\n",
    "            instructions=(\n",
    "                \"Use fetch_payment tool by passing payment id provided by the user, \"\n",
    "                \"get the order id from payment details response then fetch order details \"\n",
    "                \"using fetch_order tool and return order details in markdown format\"\n",
    "            ),\n",
    "            input=\"payment id {payment_id}\",\n",
    "            store=True,\n",
    "            stream=True\n",
    "        )\n",
    "        \n",
    "        # Use custom streaming handler to process events\n",
    "        full_response = handle_streaming_events(stream, \"Payment Confirmation\")\n",
    "        return full_response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error during payment confirmation: {e}\")\n",
    "        return None\n",
    "\n",
    "# Execute the payment confirmation (uncomment to run)\n",
    "payment_result = confirm_payment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Test Functions\n",
    "\n",
    "Uncomment any of the lines below to test individual functions:\n",
    "\n",
    "```python\n",
    "# Test individual functions:\n",
    "search_result = search_product()\n",
    "scene_result = generate_scene()\n",
    "payment_result = confirm_payment()\n",
    "```\n",
    "\n",
    "### Expected Outputs:\n",
    "- **Step 1**: Product details with images (powered by LLAMA)\n",
    "- **Step 2**: JSON response with scene description and generated image URL (powered by OpenAI)\n",
    "- **Step 3**: Payment and order details in markdown format (powered by Claude)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
